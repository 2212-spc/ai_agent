"""
智能体角色定义
定义各个专家智能体的节点函数和能力
"""
from __future__ import annotations

import logging
from typing import Any, Dict, List, Optional

from sqlalchemy.orm import Session

from .config import Settings
from .database import ToolRecord, get_active_prompt_for_agent
from .graph_agent import invoke_llm, parse_json_from_llm
from .rag_service import retrieve_context
from .shared_workspace import MultiAgentState, SharedWorkspace
from .tool_service import execute_tool

logger = logging.getLogger(__name__)


# ==================== Prompt管理辅助函数 ====================

def get_agent_prompt(
    agent_id: str,
    session: Session,
    default_prompt: str,
    **kwargs
) -> str:
    """
    获取智能体的激活prompt模板
    
    Args:
        agent_id: 智能体ID
        session: 数据库会话
        default_prompt: 默认prompt（如果数据库中没有激活的模板，使用这个）
        **kwargs: 用于替换prompt中的占位符，如 user_query, task_description 等
    
    Returns:
        处理后的prompt字符串
    """
    try:
        # 尝试从数据库获取激活的prompt
        template = get_active_prompt_for_agent(session, agent_id)
        
        if template and template.is_active:
            prompt = template.content
            logger.info(f"✅ [Prompt管理] 使用数据库中的激活模板: {template.name} (ID: {template.id})")
        else:
            prompt = default_prompt
            logger.info(f"ℹ️ [Prompt管理] 使用默认硬编码prompt (智能体: {agent_id})")
    except Exception as e:
        logger.warning(f"⚠️ [Prompt管理] 获取prompt失败，使用默认prompt: {e}")
        prompt = default_prompt
    
    # 替换占位符（增强版）
    try:
        import re
        
        # 1. 先替换双花括号为单花括号（兼容性处理）
        # 处理 {{variable}} 格式（Python f-string 转义）
        prompt = prompt.replace("{{", "{").replace("}}", "}")
        
        # 2. 替换常见的占位符
        prompt = prompt.replace("{user_query}", kwargs.get("user_query", ""))
        prompt = prompt.replace("{task_description}", kwargs.get("task_description", ""))
        prompt = prompt.replace("{analysis_context}", kwargs.get("analysis_context", ""))
        prompt = prompt.replace("{full_context}", kwargs.get("full_context", ""))
        prompt = prompt.replace("{final_answer}", kwargs.get("final_answer", ""))
        
        # 3. 替换其他自定义占位符
        for key, value in kwargs.items():
            placeholder = f"{{{key}}}"
            if placeholder in prompt:
                prompt = prompt.replace(placeholder, str(value))
        
        # 4. 检查未替换的占位符（警告）
        unmatched = re.findall(r'\{(\w+)\}', prompt)
        if unmatched:
            # 过滤掉已经替换的占位符
            replaced_placeholders = ["user_query", "task_description", "analysis_context", 
                                   "full_context", "final_answer"] + list(kwargs.keys())
            truly_unmatched = [p for p in unmatched if p not in replaced_placeholders]
            
            if truly_unmatched:
                logger.warning(f"⚠️ [Prompt管理] 未替换的占位符: {truly_unmatched}")
                # 可以选择移除未替换的占位符，或保留（这里选择保留并记录警告）
                for var in truly_unmatched:
                    # 保留占位符，但添加警告标记（可选）
                    # prompt = prompt.replace(f"{{{var}}}", f"[占位符{var}未定义]")
                    pass
        
    except Exception as e:
        logger.warning(f"⚠️ [Prompt管理] 替换占位符时出错: {e}")
    
    return prompt


# ==================== 检索专家（Retrieval Specialist） ====================

async def retrieval_specialist_node(
    state: MultiAgentState,
    settings: Settings,
    session: Session,
    tool_records: List[ToolRecord],
) -> Dict[str, Any]:
    """
    检索专家智能体
    
    职责：
    - 知识库检索（RAG）
    - 网络搜索
    - 文档查找
    
    能力：
    - 向量检索
    - 关键词搜索
    - 网页搜索工具
    """
    logger.info("🔍 [检索专家] 开始执行检索任务...")
    
    workspace = SharedWorkspace(state)
    agent_id = "retrieval_specialist"
    
    # 注册智能体
    workspace.register_agent(agent_id)
    workspace.update_agent_status(agent_id, "running")
    
    user_query = state.get("user_query", "")
    use_knowledge_base = state.get("use_knowledge_base", False)
    
    retrieval_results = {}
    thoughts = []
    observations = []
    
    try:
        # 1. 知识库检索（智能版：带置信度评估）
        if use_knowledge_base:
            try:
                logger.info("📚 执行知识库检索（带置信度评估）...")
                
                # 使用带置信度的检索函数
                from .rag_service import retrieve_context_with_confidence
                
                contexts, confidence = retrieve_context_with_confidence(
                    query=user_query,
                    settings=settings,
                    top_k=5,
                    confidence_threshold=0.3,  # 置信度阈值
                )
                
                # 根据置信度判断是否使用检索结果
                if contexts and confidence == "high":
                    # 高置信度：使用检索结果
                    retrieval_results["knowledge_base"] = [
                        {
                            "document_id": ctx.document_id,
                            "original_name": ctx.original_name,
                            "content": ctx.content[:500],
                        }
                        for ctx in contexts
                    ]
                    thoughts.append(f"✅ 从知识库检索到 {len(contexts)} 个高相关性片段")
                    observations.append(
                        f"知识库检索完成：找到 {len(contexts)} 个相关文档（高置信度）"
                    )
                    logger.info(f"✅ 知识库检索成功，置信度：{confidence}")
                    
                elif contexts and confidence == "low":
                    # 低置信度：不使用检索结果，记录日志
                    thoughts.append(f"⚠️ 知识库检索置信度较低，内容可能不相关")
                    observations.append(
                        f"知识库检索完成，但相关性较低（将优先使用其他信息源）"
                    )
                    logger.warning(f"⚠️ 知识库检索置信度低，跳过使用检索结果")
                    # 不添加到 retrieval_results，让后续流程使用工具调用
                    
                else:
                    # 未找到内容
                    thoughts.append("知识库检索未找到相关内容")
                    observations.append("知识库为空或未找到相关内容")
                    logger.info("知识库检索为空")
            
            except Exception as e:
                logger.error(f"知识库检索失败: {e}")
                thoughts.append(f"知识库检索失败: {str(e)}")
        
        # 2. 智能工具调用（通用方案）- 让LLM自己判断需要什么工具
        has_kb_results = "knowledge_base" in retrieval_results and len(retrieval_results["knowledge_base"]) > 0
        
        # 构建工具描述
        from .tool_service import BUILTIN_TOOLS
        
        tool_descriptions = []
        available_tools_map = {}  # tool_key -> tool_record
        
        for tool in tool_records:
            try:
                import json
                config = json.loads(tool.config or "{}")
                builtin_key = config.get("builtin_key")
                
                if builtin_key and builtin_key in BUILTIN_TOOLS:
                    tool_def = BUILTIN_TOOLS[builtin_key]
                    tool_descriptions.append(
                        f"- **{tool_def.name}** ({builtin_key}): {tool_def.description}"
                    )
                    available_tools_map[builtin_key] = tool
            except:
                continue
        
        if available_tools_map:
            # 使用LLM智能判断需要调用哪些工具
            tool_selection_prompt = f"""你是一个工具调用专家。请分析用户问题，判断是否需要调用工具来获取信息。

【用户问题】：{user_query}

【知识库检索状态】：{"✅ 已找到 " + str(len(retrieval_results.get("knowledge_base", []))) + " 个相关内容" if has_kb_results else "❌ 知识库无相关内容或未启用"}

【可用工具】：
{chr(10).join(tool_descriptions)}

【判断规则】：
1. 如果用户问题需要实时数据（天气、新闻、最新信息等），应该调用相应工具
2. 如果知识库已有足够信息，可以不调用工具
3. 如果知识库无相关内容，优先考虑调用工具获取信息
4. 可以同时调用多个工具（例如：查天气+搜索新闻）

请以JSON格式输出需要调用的工具：
{{
  "need_tools": true/false,
  "tools_to_call": [
    {{
      "tool_key": "get_weather",
      "reason": "用户询问天气信息",
      "arguments": {{"city": "北京"}}
    }},
    {{
      "tool_key": "web_search", 
      "reason": "需要搜索最新信息",
      "arguments": {{"query": "搜索关键词", "num_results": 5}}
    }}
  ],
  "reasoning": "判断理由"
}}

如果不需要调用工具，返回：
{{
  "need_tools": false,
  "tools_to_call": [],
  "reasoning": "知识库已有足够信息" 或 "问题无需外部数据"
}}

只返回JSON，不要其他解释。
"""
            
            try:
                logger.info("🤖 使用LLM智能判断需要调用的工具...")
                
                tool_decision, _ = await invoke_llm(
                    messages=[{"role": "user", "content": tool_selection_prompt}],
                    settings=settings,
                    temperature=0.2,
                    max_tokens=800,
                )
                
                decision_data = parse_json_from_llm(tool_decision)
                need_tools = decision_data.get("need_tools", False)
                tools_to_call = decision_data.get("tools_to_call", [])
                reasoning = decision_data.get("reasoning", "")
                
                logger.info(f"🧠 LLM判断：need_tools={need_tools}, 理由={reasoning}")
                
                if need_tools and tools_to_call:
                    thoughts.append(f"LLM决策：需要调用 {len(tools_to_call)} 个工具")
                    
                    # 执行LLM建议的工具调用
                    for tool_call in tools_to_call:
                        tool_key = tool_call.get("tool_key")
                        tool_reason = tool_call.get("reason", "")
                        tool_args = tool_call.get("arguments", {})
                        
                        if tool_key in available_tools_map:
                            try:
                                tool_record = available_tools_map[tool_key]
                                logger.info(f"🔧 执行工具：{tool_key}，原因：{tool_reason}")
                                
                                # 执行工具
                                result = execute_tool(
                                    tool=tool_record,
                                    arguments=tool_args,
                                    settings=settings,
                                    session=session,
                                )
                                
                                # 保存结果
                                retrieval_results[tool_key] = {
                                    "arguments": tool_args,
                                    "result": result,
                                }
                                
                                thoughts.append(f"✅ 工具调用成功：{tool_key}")
                                observations.append(f"工具 {tool_key} 执行完成：{tool_reason}")
                                logger.info(f"✅ 工具 {tool_key} 调用成功")
                                
                            except Exception as e:
                                logger.error(f"工具 {tool_key} 调用失败: {e}")
                                thoughts.append(f"❌ 工具 {tool_key} 调用失败: {str(e)}")
                        else:
                            logger.warning(f"⚠️ 工具 {tool_key} 不可用")
                else:
                    thoughts.append(f"LLM判断：无需调用工具（{reasoning}）")
                    logger.info(f"💡 LLM判断无需工具调用：{reasoning}")
                    
            except Exception as e:
                logger.error(f"智能工具判断失败: {e}")
                thoughts.append(f"智能工具判断失败，跳过工具调用")
        
        # 4. 存储结果到共享工作空间
        workspace.store_agent_result(agent_id, retrieval_results)
        workspace.set_shared_data("retrieval_results", retrieval_results)
        
        # 5. 发送结果消息给协调器
        workspace.send_message(
            from_agent=agent_id,
            to_agent="orchestrator",
            message_type="result",
            content={
                "status": "completed",
                "retrieval_results": retrieval_results,
                "summary": f"检索完成，共找到 {len(retrieval_results)} 类结果",
            },
        )
        
        workspace.update_agent_status(agent_id, "completed")
        
        logger.info(f"✅ [检索专家] 执行完成，找到 {len(retrieval_results)} 类结果")
        
        return {
            "agent_thoughts": {agent_id: thoughts},
            "agent_observations": {agent_id: observations},
            "retrieved_contexts": retrieval_results.get("knowledge_base", []),
        }
    
    except Exception as e:
        logger.error(f"❌ [检索专家] 执行失败: {e}", exc_info=True)
        workspace.update_agent_status(agent_id, "failed")
        workspace.send_message(
            from_agent=agent_id,
            to_agent="orchestrator",
            message_type="error",
            content={"error": str(e)},
        )
        
        return {
            "agent_thoughts": {agent_id: [f"执行失败: {str(e)}"]},
            "error": str(e),
        }


# ==================== 分析专家（Analysis Specialist） ====================

async def analysis_specialist_node(
    state: MultiAgentState,
    settings: Settings,
    session: Session,
) -> Dict[str, Any]:
    """
    分析专家智能体
    
    职责：
    - 数据分析
    - 内容理解
    - 关键信息提取
    
    能力：
    - 文本分析（使用 LLM）
    - 数据提取
    - 模式识别
    """
    logger.info("📊 [分析专家] 开始执行分析任务...")
    
    workspace = SharedWorkspace(state)
    agent_id = "analysis_specialist"
    
    workspace.register_agent(agent_id)
    workspace.update_agent_status(agent_id, "running")
    
    user_query = state.get("user_query", "")
    thoughts = []
    observations = []
    
    try:
        # 1. 获取检索专家的结果
        retrieval_results = workspace.get_shared_data("retrieval_results", {})
        
        if not retrieval_results:
            thoughts.append("未找到检索结果，使用用户查询进行分析")
            analysis_context = f"用户查询：{user_query}"
        else:
            # 构建分析上下文
            context_parts = []
            
            if "knowledge_base" in retrieval_results:
                kb_contexts = retrieval_results["knowledge_base"]
                context_parts.append(
                    f"知识库内容（{len(kb_contexts)} 个片段）:\n"
                    + "\n".join([
                        f"- {ctx.get('content', '')[:200]}"
                        for ctx in kb_contexts[:3]
                    ])
                )
            
            if "web_search" in retrieval_results:
                search_data = retrieval_results["web_search"]
                context_parts.append(
                    f"搜索结果（关键词: {search_data.get('query', '')}):\n"
                    f"{search_data.get('results', '')[:500]}"
                )
            
            analysis_context = "\n\n".join(context_parts)
            thoughts.append(f"获取到检索结果，准备分析")
        
        # 2. 使用 LLM 进行深度分析
        logger.info("🤔 使用 LLM 进行内容分析...")
        
        # 获取当前子任务的描述，以便针对性分析
        current_subtask = workspace.get_current_subtask()
        task_description = current_subtask.description if current_subtask else "深度分析内容"
        
        # 默认prompt（如果数据库中没有激活的模板，使用这个）
        default_analysis_prompt = f"""你是一个资深的技术分析专家和研究顾问。请对以下内容进行深度、系统化的分析。

【任务要求】：{task_description}

【用户问题】：{user_query}

【待分析内容】：
{analysis_context}

【分析维度】请从以下多个维度进行深入分析：

1. **核心概念识别**：
   - 识别并解释核心技术概念、术语
   - 区分基础概念与高级概念

2. **关键信息提取**：
   - 提取重要事实、数据、统计信息
   - 识别关键论点和结论
   - 标注信息来源（如有）

3. **技术原理分析**（如适用）：
   - 解释技术实现原理
   - 分析技术架构和设计思路
   - 对比不同技术方案的优劣

4. **关联性分析**：
   - 发现概念之间的逻辑关系
   - 识别因果关系、演进关系
   - 构建知识图谱式的关联

5. **趋势与洞察**：
   - 识别技术演进趋势
   - 发现潜在问题和挑战
   - 预测未来发展方向

6. **批判性思考**：
   - 指出信息的局限性
   - 识别可能存在的偏见或争议
   - 提出需要进一步验证的点

以 JSON 格式输出分析结果：
{{
  "core_concepts": [
    {{"concept": "概念名称", "explanation": "详细解释", "importance": "high|medium|low"}}
  ],
  "key_facts": [
    {{"fact": "事实描述", "source": "来源（如有）", "confidence": "high|medium|low"}}
  ],
  "key_data": [
    {{"data_point": "数据点", "value": "具体数值或描述", "context": "背景说明"}}
  ],
  "technical_principles": [
    {{"principle": "原理名称", "explanation": "原理解释", "advantages": ["优势1"], "limitations": ["局限1"]}}
  ],
  "relationships": [
    {{"from": "概念A", "to": "概念B", "relationship_type": "因果|演进|对比|补充", "description": "关系描述"}}
  ],
  "trends_insights": [
    {{"trend": "趋势描述", "evidence": "支持证据", "implications": "影响分析"}}
  ],
  "critical_notes": [
    {{"note_type": "局限性|争议点|待验证", "description": "详细说明"}}
  ],
  "analysis_summary": "全面的分析总结（300-500字）",
  "confidence_score": 0.0-1.0
}}

要求：
- 分析要深入、系统、全面
- 保持客观，避免主观臆断
- 优先使用提供的内容，标注推理部分
- 长度：500-1000字的深度分析

只返回 JSON，不要其他解释。
"""
        
        # 从数据库获取激活的prompt，如果没有则使用默认prompt
        analysis_prompt = get_agent_prompt(
            agent_id="analysis_specialist",
            session=session,
            default_prompt=default_analysis_prompt,
            user_query=user_query,
            task_description=task_description,
            analysis_context=analysis_context
        )
        
        llm_response, _ = await invoke_llm(
            messages=[{"role": "user", "content": analysis_prompt}],
            settings=settings,
            temperature=0.4,  # 稍高的温度以获得更有创意的洞察
            max_tokens=2500,  # 增加token限制以支持更深入的分析
        )
        
        # 解析 LLM 响应
        analysis_result = parse_json_from_llm(llm_response)
        
        thoughts.append("完成内容分析，提取了关键信息")
        observations.append(
            f"分析完成：识别 {len(analysis_result.get('core_topics', []))} 个核心主题，"
            f"{len(analysis_result.get('key_facts', []))} 个关键事实"
        )
        
        # 3. 存储结果
        workspace.store_agent_result(agent_id, analysis_result)
        workspace.set_shared_data("analysis_result", analysis_result)
        
        # 4. 发送结果消息
        workspace.send_message(
            from_agent=agent_id,
            to_agent="orchestrator",
            message_type="result",
            content={
                "status": "completed",
                "analysis_result": analysis_result,
            },
        )
        
        workspace.update_agent_status(agent_id, "completed")
        
        logger.info("✅ [分析专家] 分析完成")
        
        return {
            "agent_thoughts": {agent_id: thoughts},
            "agent_observations": {agent_id: observations},
        }
    
    except Exception as e:
        logger.error(f"❌ [分析专家] 执行失败: {e}", exc_info=True)
        workspace.update_agent_status(agent_id, "failed")
        workspace.send_message(
            from_agent=agent_id,
            to_agent="orchestrator",
            message_type="error",
            content={"error": str(e)},
        )
        
        return {
            "agent_thoughts": {agent_id: [f"执行失败: {str(e)}"]},
            "error": str(e),
        }


# ==================== 总结专家（Summarization Specialist） ====================

async def summarization_specialist_node(
    state: MultiAgentState,
    settings: Settings,
    session: Session,
) -> Dict[str, Any]:
    """
    总结专家智能体
    
    职责：
    - 信息整合
    - 报告生成
    - 结构化输出
    
    能力：
    - 内容总结
    - 报告撰写
    - 格式转换
    """
    logger.info("📝 [总结专家] 开始执行总结任务...")
    
    workspace = SharedWorkspace(state)
    agent_id = "summarization_specialist"
    
    workspace.register_agent(agent_id)
    workspace.update_agent_status(agent_id, "running")
    
    user_query = state.get("user_query", "")
    thoughts = []
    observations = []
    
    try:
        # 1. 收集所有智能体的结果
        retrieval_results = workspace.get_shared_data("retrieval_results", {})
        analysis_result = workspace.get_shared_data("analysis_result", {})
        
        # 2. 构建总结上下文（通用处理所有工具结果）
        context_parts = []
        
        if retrieval_results:
            context_parts.append("## 检索与工具执行结果")
            
            # 知识库检索结果
            if "knowledge_base" in retrieval_results:
                kb_contexts = retrieval_results["knowledge_base"]
                context_parts.append(
                    f"### 知识库内容（{len(kb_contexts)} 个片段）\n"
                    + "\n".join([
                        f"{i+1}. {ctx.get('content', '')[:300]}"
                        for i, ctx in enumerate(kb_contexts)
                    ])
                )
            
            # 通用工具结果处理 - 自动处理所有工具（天气、搜索、笔记等）
            tool_result_keys = [k for k in retrieval_results.keys() if k != "knowledge_base"]
            
            for tool_key in tool_result_keys:
                tool_data = retrieval_results[tool_key]
                
                # 获取工具名称
                from .tool_service import BUILTIN_TOOLS
                tool_name = BUILTIN_TOOLS.get(tool_key, type('obj', (object,), {'name': tool_key.replace('_', ' ').title()})).name
                
                # 提取结果内容
                if isinstance(tool_data, dict):
                    result_content = tool_data.get("result", "") or tool_data.get("data", "") or str(tool_data)
                else:
                    result_content = str(tool_data)
                
                # 限制长度
                result_preview = result_content[:1000] if len(result_content) > 1000 else result_content
                
                context_parts.append(
                    f"### {tool_name} 执行结果\n{result_preview}"
                )
        
        if analysis_result:
            context_parts.append("## 分析结果")
            context_parts.append(f"核心主题: {', '.join(analysis_result.get('core_topics', []))}")
            context_parts.append(f"关键发现: " + "; ".join(analysis_result.get('key_findings', [])[:3]))
            context_parts.append(f"分析总结: {analysis_result.get('analysis_summary', '')}")
        
        full_context = "\n\n".join(context_parts)
        
        thoughts.append("收集了所有智能体的结果，准备生成总结")
        
        # 3. 使用 LLM 生成综合总结
        logger.info("✍️ 使用 LLM 生成综合总结...")
        
        # 获取当前子任务描述
        current_subtask = workspace.get_current_subtask()
        task_description = current_subtask.description if current_subtask else "生成全面的总结报告"
        
        # 检查是否有深度分析结果
        has_deep_analysis = analysis_result and "core_concepts" in analysis_result
        
        # 判断信息质量（通用方案）
        has_kb_info = "knowledge_base" in retrieval_results and len(retrieval_results.get("knowledge_base", [])) > 0
        
        # 构建信息源说明 - 自动识别所有已执行的工具
        info_sources = []
        if has_kb_info:
            info_sources.append("知识库内容")
        
        # 通用处理：列出所有已执行的工具
        tool_result_keys = [k for k in retrieval_results.keys() if k != "knowledge_base"]
        if tool_result_keys:
            from .tool_service import BUILTIN_TOOLS
            for tool_key in tool_result_keys:
                tool_name = BUILTIN_TOOLS.get(tool_key, type('obj', (object,), {'name': tool_key.replace('_', ' ').title()})).name
                info_sources.append(tool_name)
        
        if info_sources:
            info_quality_note = f"✅ 已获取：{' + '.join(info_sources)}"
        else:
            info_quality_note = "⚠️ 检索信息有限，请基于自身知识合理回答，并说明信息来源的局限性"
        
        # 默认prompt（如果数据库中没有激活的模板，使用这个）
        default_summarization_prompt = f"""你是一个资深的智能助手。请基于以下信息，为用户生成清晰、准确的回答。

【任务要求】：{task_description}

【用户问题】：{user_query}

【收集到的信息】：
{full_context if full_context else "（未检索到特定信息）"}

【信息来源说明】：{info_quality_note}

【回答要求】：

1. **智能选择信息源**：
   - 如果有多个信息源（知识库、网络搜索），优先使用最相关的
   - 不要强制使用不相关的知识库内容
   - 如果网络搜索更准确，优先使用搜索结果
   - 如果信息不足或不相关，请诚实说明

2. **回答方式**：
   - **简单对话问题**：直接、简洁地回答（200-400字）
   - **信息查询**：提供准确信息，列出关键点（400-800字）
   - **研究报告**：使用 Markdown 格式，结构化组织（800-1500字）

3. **内容质量**：
   - 准确性第一：不编造不确定的信息
   - 直接回答用户问题，不要过度铺陈
   - 使用清晰的 Markdown 格式（标题、列表、引用）
   - 语言自然流畅，避免生硬的报告体

4. **特殊情况处理**：
   - 如果知识库内容与问题无关 → 忽略知识库，使用其他信息源或自身知识
   - 如果网络搜索结果更准确 → 优先使用搜索结果
   - 如果信息不足 → 坦诚说明，给出建议

5. **禁止行为**：
   - ❌ 不要强制凑字数成为冗长的报告
   - ❌ 不要使用无关的知识库内容
   - ❌ 不要编造数据或引用
   - ❌ 不要使用过于正式的报告模板（除非用户明确要求报告）

{"【补充】：已有深度分析结果，请充分利用分析专家提供的洞察" if has_deep_analysis else ""}

现在请直接、准确地回答用户问题：
"""
        
        # 从数据库获取激活的prompt，如果没有则使用默认prompt
        summarization_prompt = get_agent_prompt(
            agent_id="summarization_specialist",
            session=session,
            default_prompt=default_summarization_prompt,
            user_query=user_query,
            task_description=task_description,
            full_context=full_context if full_context else "（未检索到特定信息）",
            info_quality_note=info_quality_note,
            has_deep_analysis="已有深度分析结果，请充分利用分析专家提供的洞察" if has_deep_analysis else ""
        )
        
        final_answer, _ = await invoke_llm(
            messages=[{"role": "user", "content": summarization_prompt}],
            settings=settings,
            temperature=0.6,  # 平衡创造性和准确性
            max_tokens=3000,  # 增加token以支持更长的报告
        )
        
        # 检查是否是错误消息
        if final_answer.startswith("LLM 调用") or len(final_answer) < 50:
            logger.warning(f"⚠️ [总结专家] LLM 响应异常: {final_answer}")
            # 降级策略：生成简单总结
            fallback_answer = f"""# {user_query}

## 执行摘要
本次多智能体协作完成了以下工作：

### 检索结果
{"✅ 已完成知识库检索和网络搜索" if retrieval_results else "⚠️ 检索信息有限"}

### 分析结果
{"✅ 已完成深度分析" if analysis_result else "⚠️ 分析信息有限"}

## 说明
由于LLM响应超时或异常，系统生成了简化版报告。建议：
1. 重新提交问题
2. 简化问题描述
3. 检查网络连接

原始错误信息：{final_answer}
"""
            final_answer = fallback_answer
            thoughts.append("LLM响应异常，使用降级策略生成简化报告")
        else:
            thoughts.append("生成了综合总结回答")
        
        observations.append(f"总结完成，生成回答长度：{len(final_answer)} 字符")
        
        # 4. 存储结果
        workspace.store_agent_result(agent_id, {"final_answer": final_answer})
        workspace.set_shared_data("final_answer", final_answer)
        
        # 5. 发送结果消息
        workspace.send_message(
            from_agent=agent_id,
            to_agent="orchestrator",
            message_type="result",
            content={
                "status": "completed",
                "final_answer": final_answer,
            },
        )
        
        workspace.update_agent_status(agent_id, "completed")
        
        logger.info("✅ [总结专家] 总结完成")
        
        return {
            "agent_thoughts": {agent_id: thoughts},
            "agent_observations": {agent_id: observations},
            "final_answer": final_answer,
        }
    
    except Exception as e:
        logger.error(f"❌ [总结专家] 执行失败: {e}", exc_info=True)
        workspace.update_agent_status(agent_id, "failed")
        workspace.send_message(
            from_agent=agent_id,
            to_agent="orchestrator",
            message_type="error",
            content={"error": str(e)},
        )
        
        return {
            "agent_thoughts": {agent_id: [f"执行失败: {str(e)}"]},
            "error": str(e),
        }


# ==================== 验证专家（Verification Specialist） ====================

async def verification_specialist_node(
    state: MultiAgentState,
    settings: Settings,
    session: Session,
) -> Dict[str, Any]:
    """
    验证专家智能体（可选）
    
    职责：
    - 质量检查
    - 事实核查
    - 一致性验证
    
    能力：
    - 信息验证
    - 质量评估
    """
    logger.info("✔️ [验证专家] 开始执行验证任务...")
    
    workspace = SharedWorkspace(state)
    agent_id = "verification_specialist"
    
    workspace.register_agent(agent_id)
    workspace.update_agent_status(agent_id, "running")
    
    thoughts = []
    observations = []
    
    try:
        # 1. 获取最终答案
        final_answer = workspace.get_shared_data("final_answer", "")
        
        if not final_answer:
            thoughts.append("未找到最终答案，跳过验证")
            workspace.update_agent_status(agent_id, "skipped")
            return {
                "agent_thoughts": {agent_id: thoughts},
            }
        
        # 2. 使用 LLM 进行质量评估
        logger.info("🔍 使用 LLM 进行质量验证...")
        
        # 默认prompt（如果数据库中没有激活的模板，使用这个）
        default_verification_prompt = f"""请评估以下回答的质量：

回答内容：
{final_answer}

请从以下维度评估（0-10分）：
1. 准确性：信息是否准确可靠
2. 完整性：是否全面回答了问题
3. 清晰度：表达是否清晰易懂
4. 相关性：是否与问题相关

以 JSON 格式输出评估结果：
{{
  "accuracy_score": 0-10,
  "completeness_score": 0-10,
  "clarity_score": 0-10,
  "relevance_score": 0-10,
  "overall_score": 0-10,
  "issues": ["问题1", "问题2", ...],
  "suggestions": ["建议1", "建议2", ...],
  "verdict": "通过" 或 "需要改进"
}}

只返回 JSON，不要其他解释。
"""
        
        # 从数据库获取激活的prompt，如果没有则使用默认prompt
        verification_prompt = get_agent_prompt(
            agent_id="verification_specialist",
            session=session,
            default_prompt=default_verification_prompt,
            final_answer=final_answer
        )
        
        llm_response, _ = await invoke_llm(
            messages=[{"role": "user", "content": verification_prompt}],
            settings=settings,
            temperature=0.2,
            max_tokens=800,
        )
        
        verification_result = parse_json_from_llm(llm_response)
        
        overall_score = verification_result.get("overall_score", 7)
        verdict = verification_result.get("verdict", "通过")
        
        thoughts.append(f"完成质量验证，总分：{overall_score}/10")
        observations.append(f"验证结果：{verdict}，总分 {overall_score}/10")
        
        # 3. 存储结果
        workspace.store_agent_result(agent_id, verification_result)
        workspace.set_shared_data("verification_result", verification_result)
        
        # 4. 发送结果消息
        workspace.send_message(
            from_agent=agent_id,
            to_agent="orchestrator",
            message_type="result",
            content={
                "status": "completed",
                "verification_result": verification_result,
            },
        )
        
        workspace.update_agent_status(agent_id, "completed")
        
        logger.info(f"✅ [验证专家] 验证完成，结果：{verdict}")
        
        return {
            "agent_thoughts": {agent_id: thoughts},
            "agent_observations": {agent_id: observations},
            "quality_score": overall_score / 10.0,
        }
    
    except Exception as e:
        logger.error(f"❌ [验证专家] 执行失败: {e}", exc_info=True)
        workspace.update_agent_status(agent_id, "failed")
        workspace.send_message(
            from_agent=agent_id,
            to_agent="orchestrator",
            message_type="error",
            content={"error": str(e)},
        )
        
        return {
            "agent_thoughts": {agent_id: [f"执行失败: {str(e)}"]},
            "error": str(e),
        }


# ==================== 智能体注册表 ====================

AGENT_REGISTRY = {
    "retrieval_specialist": {
        "name": "检索专家",
        "description": "负责知识库检索和网络搜索",
        "node_function": retrieval_specialist_node,
        "capabilities": ["knowledge_base_retrieval", "web_search", "document_analysis"],
    },
    "analysis_specialist": {
        "name": "分析专家",
        "description": "负责数据分析和内容理解",
        "node_function": analysis_specialist_node,
        "capabilities": ["text_analysis", "data_extraction", "pattern_recognition"],
    },
    "summarization_specialist": {
        "name": "总结专家",
        "description": "负责信息整合和报告生成",
        "node_function": summarization_specialist_node,
        "capabilities": ["content_summarization", "report_generation", "format_conversion"],
    },
    "verification_specialist": {
        "name": "验证专家",
        "description": "负责质量检查和事实核查（可选）",
        "node_function": verification_specialist_node,
        "capabilities": ["quality_check", "fact_verification", "consistency_validation"],
    },
}


def get_agent_by_id(agent_id: str) -> Optional[Dict[str, Any]]:
    """根据ID获取智能体信息"""
    return AGENT_REGISTRY.get(agent_id)


def list_available_agents() -> List[Dict[str, Any]]:
    """列出所有可用的智能体"""
    return [
        {
            "id": agent_id,
            "name": info["name"],
            "description": info["description"],
            "capabilities": info["capabilities"],
        }
        for agent_id, info in AGENT_REGISTRY.items()
    ]


def get_default_prompts() -> List[Dict[str, Any]]:
    """获取所有默认的prompt模板（硬编码的原始prompt）"""
    return [
        {
            "agent_id": "retrieval_specialist",
            "name": "检索专家-默认模板",
            "description": "系统默认的检索专家说明模板，作为示例参考（检索专家主要执行检索操作，不直接使用LLM）",
            "content": """检索专家智能体职责说明：

【智能体角色】：检索专家（Retrieval Specialist）

【主要职责】：
1. 知识库检索（RAG）
   - 使用向量检索从知识库中查找相关内容
   - 支持语义搜索和关键词匹配
   - 返回最相关的文档片段

2. 网络搜索
   - 当用户查询包含搜索关键词时，执行网络搜索
   - 获取最新的网络信息
   - 整合搜索结果

3. 文档查找
   - 分析用户查询，确定需要检索的文档类型
   - 执行相应的检索策略

【工作流程】：
1. 接收用户查询：{user_query}
2. 判断是否需要知识库检索（根据use_knowledge_base标志）
3. 判断是否需要网络搜索（根据查询关键词）
4. 执行相应的检索操作
5. 整理检索结果并返回给协调器

【输出格式】：
检索结果以结构化格式返回，包括：
- knowledge_base: 知识库检索结果列表
- web_search: 网络搜索结果（如果执行了搜索）

【注意事项】：
- 检索专家主要负责信息检索，不进行内容分析
- 检索结果会传递给分析专家进行进一步处理
- 确保检索结果的准确性和相关性"""
        },
        {
            "agent_id": "analysis_specialist",
            "name": "分析专家-默认模板",
            "description": "系统默认的分析专家prompt，作为示例参考",
            "content": """你是一个资深的技术分析专家和研究顾问。请对以下内容进行深度、系统化的分析。

【任务要求】：{task_description}

【用户问题】：{user_query}

【待分析内容】：
{analysis_context}

【分析维度】请从以下多个维度进行深入分析：

1. **核心概念识别**：
   - 识别并解释核心技术概念、术语
   - 区分基础概念与高级概念

2. **关键信息提取**：
   - 提取重要事实、数据、统计信息
   - 识别关键论点和结论
   - 标注信息来源（如有）

3. **技术原理分析**（如适用）：
   - 解释技术实现原理
   - 分析技术架构和设计思路
   - 对比不同技术方案的优劣

4. **关联性分析**：
   - 发现概念之间的逻辑关系
   - 识别因果关系、演进关系
   - 构建知识图谱式的关联

5. **趋势与洞察**：
   - 识别技术演进趋势
   - 发现潜在问题和挑战
   - 预测未来发展方向

6. **批判性思考**：
   - 指出信息的局限性
   - 识别可能存在的偏见或争议
   - 提出需要进一步验证的点

以 JSON 格式输出分析结果：
{{
  "core_concepts": [
    {{"concept": "概念名称", "explanation": "详细解释", "importance": "high|medium|low"}}
  ],
  "key_facts": [
    {{"fact": "事实描述", "source": "来源（如有）", "confidence": "high|medium|low"}}
  ],
  "key_data": [
    {{"data_point": "数据点", "value": "具体数值或描述", "context": "背景说明"}}
  ],
  "technical_principles": [
    {{"principle": "原理名称", "explanation": "原理解释", "advantages": ["优势1"], "limitations": ["局限1"]}}
  ],
  "relationships": [
    {{"from": "概念A", "to": "概念B", "relationship_type": "因果|演进|对比|补充", "description": "关系描述"}}
  ],
  "trends_insights": [
    {{"trend": "趋势描述", "evidence": "支持证据", "implications": "影响分析"}}
  ],
  "critical_notes": [
    {{"note_type": "局限性|争议点|待验证", "description": "详细说明"}}
  ],
  "analysis_summary": "全面的分析总结（300-500字）",
  "confidence_score": 0.0-1.0
}}

要求：
- 分析要深入、系统、全面
- 保持客观，避免主观臆断
- 优先使用提供的内容，标注推理部分
- 长度：500-1000字的深度分析

只返回 JSON，不要其他解释。"""
        },
        {
            "agent_id": "summarization_specialist",
            "name": "总结专家-默认模板",
            "description": "系统默认的总结专家prompt，作为示例参考",
            "content": """你是一个资深的研究报告撰写专家。请基于以下信息，为用户生成一份高质量、结构化的研究报告或答案。

【任务要求】：{task_description}

【用户问题】：{user_query}

【收集到的信息】：
{full_context}

【报告撰写要求】：

1. **结构化组织**：
   - 使用清晰的 Markdown 格式
   - 合理的标题层级（# ## ### ）
   - 如果是研究报告，包含：引言、主要内容、结论
   - 如果是技术分析，包含：概述、技术原理、应用案例、趋势分析

2. **内容深度**：
   - 不要只是罗列信息，要进行深度整合和提炼
   - 建立不同信息点之间的逻辑联系
   - 提供清晰的论证和推理过程
   - 突出关键发现和核心洞察

3. **表达质量**：
   - 语言流畅、专业、准确
   - 避免重复和冗余
   - 使用具体的数据和案例支撑论点
   - 适当使用列表、表格等形式

4. **信息来源**：
   - 优先使用提供的检索结果和分析结果
   - 如果引用具体数据或观点，可注明来源
   - 区分事实陈述和推理结论

5. **完整性**：
   - 全面回答用户提出的所有问题点
   - 不遗漏关键信息
   - 如果信息不足，明确指出

6. **长度要求**：
   - 简单问题：300-600字
   - 中等复杂度：600-1200字
   - 复杂研究报告：1200-2000字

【特别注意】：
- 这是多智能体协作的最终输出，要体现高质量
- 整合所有前序智能体的工作成果
- 确保报告的专业性和可读性
{has_deep_analysis}

现在请生成最终报告："""
        },
        {
            "agent_id": "verification_specialist",
            "name": "验证专家-默认模板",
            "description": "系统默认的验证专家prompt，作为示例参考",
            "content": """请评估以下回答的质量：

回答内容：
{final_answer}

请从以下维度评估（0-10分）：
1. 准确性：信息是否准确可靠
2. 完整性：是否全面回答了问题
3. 清晰度：表达是否清晰易懂
4. 相关性：是否与问题相关

以 JSON 格式输出评估结果：
{{
  "accuracy_score": 0-10,
  "completeness_score": 0-10,
  "clarity_score": 0-10,
  "relevance_score": 0-10,
  "overall_score": 0-10,
  "issues": ["问题1", "问题2", ...],
  "suggestions": ["建议1", "建议2", ...],
  "verdict": "通过" 或 "需要改进"
}}

只返回 JSON，不要其他解释。"""
        },
    ]

